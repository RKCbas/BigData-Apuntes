{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una empresa farmacéutica internacional está considerando realizar pruebas clínicas de una nueva vacuna/tratamiento para COVID-19 en México. Para tomar decisiones informadas sobre la ubicación y el alcance de las pruebas, la empresa necesita analizar datos epidemiológicos y demográficos relevantes. Con no menos de 1,000,000 registros.\n",
    "\n",
    "### Adquisición y Limpieza de Datos:\n",
    "\n",
    "   - Identificar y evaluar fuentes de datos confiables sobre COVID-19 en México.\n",
    "   - Descargar y transformar datos en formatos adecuados (CSV, JSON).\n",
    "   - Limpiar y preparar los datos para el análisis. Por ejemplo: fecha (mm-dd-yyyy), no ids, si no nombres.\n",
    "\n",
    "### Ingesta de Datos en Elasticsearch:\n",
    "\n",
    "   - Crear un índice en Elasticsearch para almacenar los datos de COVID-19.\n",
    "   - Definir mappings para optimizar las búsquedas y el análisis.\n",
    "   - Cargar los datos en Elasticsearch utilizando herramientas como Python, Pandas y la librería elasticsearch.\n",
    "   - Definir queries básicas\n",
    "\n",
    "## Solución\n",
    "\n",
    "Para la solución de esta problemática encontramos un dataset de datos abiertos de la dirección de epidemiología de Mexico ([Datos](https://www.gob.mx/salud/documentos/datos-abiertos-152127)) en este dataset vamos a guardar en un df los datos cargados desde el csv y después vamos a modificar los datos para ponerlos en el formato solicitado para después guardarlo todo en un json para que después lo podamos subir a elastic search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ElasticSearchProvider import ElasticSearchProvider\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificar datos\n",
    "\n",
    "### Rutas de archivos\n",
    "\n",
    "Primeramente vamos a definir variables que nos van a ayudar con la direccion de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"Datos.json\"\n",
    "csv_file_path = \"COVID19MEXICO2020.csv\"\n",
    "excel_catalog_path = \"Catálogos.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: Debido a que las rutas de los archivos que vamos a utilizar se repiten muchas veces vamos a declarar variables que contengan los nombres de los archivos\n",
    "\n",
    "### Entidades y municipios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un pequeño diccionario que nos va a ayudar a obtener el nombre de la entidad dependiendo de su id\n",
    "ENTIDADES_DICT = {\n",
    "    1: \"AGUASCALIENTES\",\n",
    "    2: \"BAJA CALIFORNIA\",\n",
    "    3: \"BAJA CALIFORNIA SUR\",\n",
    "    4: \"CAMPECHE\",\n",
    "    5: \"COAHUILA DE ZARAGOZA\",\n",
    "    6: \"COLIMA\",\n",
    "    7: \"CHIAPAS\",\n",
    "    8: \"CHIHUAHUA\",\n",
    "    9: \"CIUDAD DE MÉXICO\",\n",
    "    10: \"DURANGO\",\n",
    "    11: \"GUANAJUATO\",\n",
    "    12: \"GUERRERO\",\n",
    "    13: \"HIDALGO\",\n",
    "    14: \"JALISCO\",\n",
    "    15: \"MÉXICO\",\n",
    "    16: \"MICHOACÁN DE OCAMPO\",\n",
    "    17: \"MORELOS\",\n",
    "    18: \"NAYARIT\",\n",
    "    19: \"NUEVO LEÓN\",\n",
    "    20: \"OAXACA\",\n",
    "    21: \"PUEBLA\",\n",
    "    22: \"QUERÉTARO\",\n",
    "    23: \"QUINTANA ROO\",\n",
    "    24: \"SAN LUIS POTOSÍ\",\n",
    "    25: \"SINALOA\",\n",
    "    26: \"SONORA\",\n",
    "    27: \"TABASCO\",\n",
    "    28: \"TAMAULIPAS\",\n",
    "    29: \"TLAXCALA\",\n",
    "    30: \"VERACRUZ DE IGNACIO DE LA LLAVE\",\n",
    "    31: \"YUCATÁN\",\n",
    "    32: \"ZACATECAS\",\n",
    "    36: \"ESTADOS UNIDOS MEXICANOS\",\n",
    "    97: \"NO APLICA\",\n",
    "    98: \"SE IGNORA\",\n",
    "    99: \"NO ESPECIFICADO\"\n",
    "}\n",
    "\n",
    "# Creamos una función que utilizando le entidad_id nos regrese el nombre de la entidad en base al diccionario de arriba\n",
    "def obtener_nombre_entidad(entidad_id) -> str:\n",
    "    \"\"\"\n",
    "    Devuelve el nombre de la entidad correspondiente al ID proporcionado.\n",
    "    Si el ID no está en el diccionario, devuelve el ID original.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ENTIDADES_DICT.get(entidad_id, entidad_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al obtener el nombre de la entidad para ID {entidad_id}: {e}\")\n",
    "        return entidad_id\n",
    "\n",
    "# Cargar los catálogos de entidades y municipios desde el archivo Excel\n",
    "entidades_df = pd.read_excel(excel_catalog_path, sheet_name=\"Catálogo de ENTIDADES\")\n",
    "municipios_df = pd.read_excel(excel_catalog_path, sheet_name=\"Catálogo MUNICIPIOS\")\n",
    "\n",
    "# Renombrar columnas para facilitar el merge\n",
    "entidades_df.rename(columns={\"CLAVE_ENTIDAD\": \"ENTIDAD_RES\", \"ENTIDAD_FEDERATIVA\": \"NOMBRE_ENTIDAD\"}, inplace=True)\n",
    "municipios_df.rename(columns={\"CLAVE_ENTIDAD\": \"ENTIDAD_RES\", \"CLAVE_MUNICIPIO\": \"MUNICIPIO_RES\", \"MUNICIPIO\": \"NOMBRE_MUNICIPIO\"}, inplace=True)\n",
    "\n",
    "# delete ABREVIATURA column from entidades_df debido a que no lo vamos a utilizar\n",
    "entidades_df.drop(columns=[\"ABREVIATURA\"], inplace=True)\n",
    "\n",
    "# Definir el mapeo de tipos de datos para las columnas\n",
    "dtype_mapping = {\n",
    "    \"PAIS_NACIONALIDAD\": \"str\",  # Columna 38\n",
    "    \"PAIS_ORIGEN\": \"str\",       # Columna 39\n",
    "}\n",
    "\n",
    "# cargar el df desde el csv\n",
    "df = pd.read_csv(csv_file_path, dtype=dtype_mapping)\n",
    "\n",
    "# Hacer merge para agregar los nombres de entidad y municipio\n",
    "df = df.merge(entidades_df, on=\"ENTIDAD_RES\", how=\"left\")\n",
    "df = df.merge(municipios_df, on=[\"ENTIDAD_RES\", \"MUNICIPIO_RES\"], how=\"left\")\n",
    "\n",
    "# Crear el campo RES como un diccionario\n",
    "df[\"RES\"] = df.apply(\n",
    "    lambda row: {\n",
    "        \"IS_ENTIDAD\": row[\"ENTIDAD_RES\"],\n",
    "        \"ENTIDAD\": row[\"NOMBRE_ENTIDAD\"],\n",
    "        \"ID_MUNICIPIO\": row[\"MUNICIPIO_RES\"],\n",
    "        \"MUNICIPIO\": row[\"NOMBRE_MUNICIPIO\"]\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# delete the columns \"ENTIDAD_RES\", \"MUNICIPIO_RES\", \"NOMBRE_ENTIDAD\", \"NOMBRE_MUNICIPIO\"\n",
    "df.drop(columns=[\"ENTIDAD_RES\", \"MUNICIPIO_RES\", \"NOMBRE_ENTIDAD\", \"NOMBRE_MUNICIPIO\"], inplace=True)\n",
    "\n",
    "# Leave only the first 1000000 rows\n",
    "df = df.head(1000000)\n",
    "\n",
    "# Save the DataFrame to a JSON file\n",
    "df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "print(\"Archivo JSON creado\")\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "# Change \"ENTIDAD_UM\", \"ENTIDAD_NAC\" to a dictionary of the id and the name of the entity\n",
    "if \"ENTIDAD_UM\" in df.columns:\n",
    "    df[\"ENTIDAD_UM\"] = df[\"ENTIDAD_UM\"].apply(\n",
    "        lambda entidad_id: {\n",
    "            \"ID\": entidad_id,\n",
    "            \"NOMBRE\": obtener_nombre_entidad(int(entidad_id)) if pd.notnull(entidad_id) else None\n",
    "        }\n",
    "    )\n",
    "\n",
    "if \"ENTIDAD_NAC\" in df.columns:\n",
    "    df[\"ENTIDAD_NAC\"] = df[\"ENTIDAD_NAC\"].apply(\n",
    "        lambda entidad_id: {\n",
    "            \"ID\": entidad_id,\n",
    "            \"NOMBRE\": obtener_nombre_entidad(int(entidad_id)) if pd.notnull(entidad_id) else None\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Guardar el DataFrame modificado en el archivo JSON\n",
    "df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "print(\"Archivo JSON actualizado con los cambios en 'ENTIDAD_UM' y 'ENTIDAD_NAC'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: Con esto cargamos los datos del csv y le hacemos algunas modificaciones básicas donde guardamos unicamente lso primeros 1´000,000 registros y también reorganizamos las entidades para que cuando se guarden en el json se guarde el id y el nombre de la entidad y para la residencia se guarda tanto la entidad como el municipio con el sus id´s, el mapping para estas modificaciones seria algo similar a esto:\n",
    "```json\n",
    "    \"ENTIDAD_UM\": {\n",
    "        \"properties\": {\n",
    "          \"ID\": { \"type\": \"integer\" },\n",
    "          \"NOMBRE\": { \"type\": \"keyword\" }\n",
    "        }\n",
    "      },\n",
    "      \"ENTIDAD_NAC\": {\n",
    "        \"properties\": {\n",
    "          \"ID\": { \"type\": \"integer\" },\n",
    "          \"NOMBRE\": { \"type\": \"keyword\" }\n",
    "        }\n",
    "      },\n",
    "      \"RES\": {\n",
    "        \"properties\": {\n",
    "          \"id_entidad\": { \"type\": \"integer\" },\n",
    "          \"entidad\": { \"type\": \"keyword\" },\n",
    "          \"id_municipio\": { \"type\": \"integer\" },\n",
    "          \"municipio\": { \"type\": \"keyword\" }\n",
    "        }\n",
    "      }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificar país origen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "# Check and convert 'PAIS_ORIGEN' column values\n",
    "if \"97\" in df[\"PAIS_ORIGEN\"].values:\n",
    "    df[\"PAIS_ORIGEN\"] = 'No aplica'\n",
    "    df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "    print(\"Valores de 'PAIS_ORIGEN' actualizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: debido a que el df que utilizamos en el campo \"PAIS_ORIGEN\" solo cuenta con el id 97 que significa que no aplica vamos a sustituir el id con su valor en el mismo campo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificar fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "# List of date columns\n",
    "date_columns = [\n",
    "    'FECHA_ACTUALIZACION',\n",
    "    'FECHA_INGRESO',\n",
    "    'FECHA_SINTOMAS',\n",
    "    'FECHA_DEF'\n",
    "]\n",
    "\n",
    "# Check and convert date format for each date column\n",
    "for date_column in date_columns:\n",
    "    if date_column in df.columns:\n",
    "        # Replace invalid dates with empty strings\n",
    "        if '9999-99-99' in df[date_column].values:\n",
    "            df[date_column] = df[date_column].replace('9999-99-99', '')\n",
    "\n",
    "        if not df[date_column].str.match(r'\\d{2}-\\d{2}-\\d{4}').all():\n",
    "            # Convert the date format\n",
    "            df[date_column] = pd.to_datetime(df[date_column], errors='coerce').dt.strftime('%m-%d-%Y')\n",
    "\n",
    "            # Save the modified DataFrame back to JSON\n",
    "            df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "            print(f\"Formato de fecha actualizado para la columna {date_column}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: como se solicita tenemos que cambiar el formato de las fechas de df entonces primeramente identificamos que hay 4 campos que son de tipo fecha entonces vamos a crear un arreglo para iterar y modificar estos campos 1 por 1 y se hizo una modificación que debido a que elasticSearch no acepta fechas en formato de 99-99-9999 que indican que el paciente no tiene esta fecha pues vamos a cambiarlo por un campo vació\n",
    "\n",
    "### Modificar resultado de laboratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "# Check and convert 'RESULTADO_LAB' column values\n",
    "if df[\"RESULTADO_LAB\"].isin([1, 2, 3, 4, 97]).any():\n",
    "    df[\"RESULTADO_LAB\"] = df[\"RESULTADO_LAB\"].replace({\n",
    "        1: 'Positivo', \n",
    "        2: 'Negativo',\n",
    "        3: 'Pendiente',\n",
    "        4: 'Resultado no aplicable',\n",
    "        97: 'No se realizó la prueba'\n",
    "        })\n",
    "\n",
    "    # Save the modified DataFrame back to JSON\n",
    "    df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "    print(\"Valores de 'RESULTADO_LAB' actualizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: simplemente remplazamos los id´s por su valores correspondientes\n",
    "\n",
    "### Modificar clasificación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "# Check and convert 'CLASIFICACION_FINAL' column values\n",
    "if df[\"CLASIFICACION_FINAL\"].isin([1, 2, 3, 4, 5, 6, 7]).any():\n",
    "    df[\"CLASIFICACION_FINAL\"] = df[\"CLASIFICACION_FINAL\"].replace({\n",
    "        1: 'CASO DE COVID-19 CONFIRMADO POR ASOCIACIÓN CLÍNICA EPIDEMIOLÓGICA',\n",
    "        2: 'CASO DE COVID-19 CONFIRMADO POR COMITÉ DE DICTAMINACIÓN',\n",
    "        3: 'CASO DE SARS-COV-2 CONFIRMADO',\n",
    "        4: 'INVÁLIDO POR LABORATORIO',\n",
    "        5: 'NO REALIZADO POR LABORATORIO',\n",
    "        6: 'CASO SOSPECHOSO',\n",
    "        7: 'NEGATIVO A SARS-COV-2',\n",
    "        })\n",
    "\n",
    "    # Save the modified DataFrame back to JSON\n",
    "    df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "    print(\"Valores de 'CLASIFICACION_FINAL' actualizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: simplemente remplazamos los id´s por su valores correspondientes\n",
    "\n",
    "### Modificar sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "# Check and convert 'SEXO' column values\n",
    "if df[\"SEXO\"].isin([1, 2, 99]).any():\n",
    "    df[\"SEXO\"] = df[\"SEXO\"].replace({2: 'Hombre', 1: 'Mujer', 99: 'No Especificado'})\n",
    "\n",
    "    # Save the modified DataFrame back to JSON\n",
    "    df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "    print(\"Valores de 'SEXO' actualizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: simplemente remplazamos los id´s por su valores correspondientes\n",
    "\n",
    "### Modificar le tipo de paciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "# Check and convert 'TIPO_PACIENTE' column values\n",
    "if df[\"TIPO_PACIENTE\"].isin([1, 2, 99]).any():\n",
    "    df[\"TIPO_PACIENTE\"] = df[\"TIPO_PACIENTE\"].replace({1: 'Ambulatorio', 2: 'Hospitalizado', 99: 'No Especificado'})\n",
    "\n",
    "    # Save the modified DataFrame back to JSON\n",
    "    df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "    print(\"Valores de 'TIPO_PACIENTE' actualizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: simplemente remplazamos los id´s por su valores correspondientes\n",
    "\n",
    "### Modificaciones de origen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "# Check and convert 'ORIGEN' column values\n",
    "if df[\"ORIGEN\"].isin([1, 2, 99]).any():\n",
    "    df[\"ORIGEN\"] = df[\"ORIGEN\"].replace({1: 'USMER', 2: 'Fuera de USMER', 99: 'No Especificado'})\n",
    "\n",
    "    # Save the modified DataFrame back to JSON\n",
    "    df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "    print(\"Valores de 'ORIGEN' actualizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: simplemente remplazamos los id´s por su valores correspondientes\n",
    "\n",
    "### Modificaciones de sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "# Check and convert 'SECTOR' column values\n",
    "if df[\"SECTOR\"].isin([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 99]).any():\n",
    "    df[\"SECTOR\"] = df[\"SECTOR\"].replace({\n",
    "        1: 'CRUZ ROJA',\n",
    "        2: 'DIF',\n",
    "        3: 'ESTATAL',\n",
    "        4: 'IMSS',\n",
    "        5: 'IMSS-BIENESTAR',\n",
    "        6: 'ISSSTE',\n",
    "        7: 'MUNICIPAL',\n",
    "        8: 'PEMEX',\n",
    "        9: 'PRIVADA',\n",
    "        10: 'SEDENA',\n",
    "        11: 'SEMAR',\n",
    "        12: 'SSA',\n",
    "        13: 'UNIVERSITARIO',\n",
    "        14: 'CIJ',\n",
    "        15: 'IMSS Bienestar OPD',\n",
    "        99: 'No Especificado'\n",
    "    })\n",
    "\n",
    "    # Save the modified DataFrame back to JSON\n",
    "    df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "    print(\"Valores de 'SECTOR' actualizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: simplemente remplazamos los id´s por su valores correspondientes\n",
    "\n",
    "### Modificaciones de nacionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "# Check and convert 'Nacionalidad' column values\n",
    "if df[\"NACIONALIDAD\"].isin([1, 2, 99]).any():\n",
    "    df[\"NACIONALIDAD\"] = df[\"NACIONALIDAD\"].replace({1: 'Mexicana', 2: 'Extranjera', 99: 'No Especificado'})\n",
    "\n",
    "    # Save the modified DataFrame back to JSON\n",
    "    df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "    print(\"Valores de 'NACIONALIDAD' actualizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: simplemente remplazamos los id´s por su valores correspondientes\n",
    "\n",
    "### Modificaciones de columnas estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file into a DataFrame\n",
    "df = pd.read_json(json_file_path, orient=\"records\", lines=False)\n",
    "\n",
    "Columnas_estándar = [\n",
    "    \"INTUBADO\",\n",
    "    \"NEUMONIA\",\n",
    "    \"EMBARAZO\",\n",
    "    \"HABLA_LENGUA_INDIG\",\n",
    "    \"INDIGENA\",\n",
    "    \"DIABETES\",\n",
    "    \"EPOC\",\n",
    "    \"ASMA\",\n",
    "    \"INMUSUPR\",\n",
    "    \"HIPERTENSION\",\n",
    "    \"OTRA_COM\",\n",
    "    \"CARDIOVASCULAR\",\n",
    "    \"OBESIDAD\",\n",
    "    \"RENAL_CRONICA\",\n",
    "    \"TABAQUISMO\",\n",
    "    \"OTRO_CASO\",\n",
    "    \"TOMA_MUESTRA_LAB\",\n",
    "    \"TOMA_MUESTRA_ANTIGENO\",\n",
    "    \"MIGRANTE\",\n",
    "    \"UCI\"\n",
    "]\n",
    "\n",
    "for columna in Columnas_estándar:\n",
    "    if df[columna].isin([1, 2, 97, 98, 99]).any():\n",
    "        df[columna] = df[columna].replace({1: 'Sí', 2: 'No', 97: 'No aplica', 98: 'Se ignora', 99: 'No especificado'})\n",
    "\n",
    "        # Save the modified DataFrame back to JSON\n",
    "        df.to_json(json_file_path, orient=\"records\", lines=False, indent=4)\n",
    "        print(f\"Valores de '{columna}' actualizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Descripción: simplemente remplazamos los id´s por su valores correspondientes\n",
    "\n",
    "## Cargar los datos a Elastic Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
